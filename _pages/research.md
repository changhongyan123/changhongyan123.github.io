---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---

My research interests focus on the privacy and fairness aspects of machine learning systems, federated learning, and Large Language Models. I am particularly interested in:

## Privacy in Machine Learning

I investigate privacy risks in machine learning, particularly how adversaries can exploit model information to infer sensitive details about training data. My work includes developing efficient privacy auditing techniques for federated learning systems that have minimal overhead and can be seamlessly integrated into the training process.

## Fairness in Machine Learning

My research examines the fairness implications of machine learning algorithms, including how model randomness impacts group fairness measures and how bias propagates in federated learning environments. I study the complex interplay between fairness constraints and privacy, revealing that fairness objectives can sometimes amplify privacy vulnerabilities.

## Security of Large Language Models

I study the security of large language models, with a focus on two key areas:

- **Privacy and Memorization**: My work on context-aware membership inference attacks reveals how LLMs memorize training data in context-dependent ways. By analyzing perplexity dynamics across token sequences, our novel attack significantly outperforms traditional loss-based approaches, providing new insights into LLM memorization patterns.

- **Watermarking**: My research demonstrates how adversaries can perform smoothing attacks to remove watermarks from generated text without significantly degrading quality, revealing fundamental limitations in current watermarking methods.

## Research Vision

My overarching goal is to develop machine learning systems that maintain high utility while preserving privacy and ensuring fairness across diverse groups. This interdisciplinary research connects computer security, privacy, machine learning, and the social implications of AI technologies. 