---
layout: about
title: about
permalink: /
# subtitle: Postdoc at MBZUAI. Trustworthy Machine Learning. Privacy & LLMs.

profile:
  align: right
  image: myself.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <div class="social" style="font-size: 1.5em; margin-top: 10px;">
      <a href="mailto:changhongyan0530@gmail.com" title="Email" style="margin-right: 15px;"><i class="fa-solid fa-envelope"></i></a>
      <a href="https://github.com/changhongyan123" title="GitHub" style="margin-right: 15px;"><i class="fa-brands fa-github"></i></a>
      <a href="https://scholar.google.com/citations?user=5d1AHgIAAAAJ" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
    </div>

selected_papers: false # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page

announcements:
  enabled: false # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

I am Hongyan Chang (常红燕), a postdoc at MBZUAI, working with Prof. [Ting Yu](https://mbzuai.ac.ae/study/faculty/ting-yu/). I obtained my Ph.D. from National University of Singapore working under the supervision of [Reza Shokri](https://www.comp.nus.edu.sg/~reza/).

My research interests are in trustworthy machine learning, with a focus on the privacy and accountability of large language models (LLMs):

- **Evaluating the risks of LLMs**: Understanding and quantifying vulnerabilities in modern language models and their applications
- **Machine-generated text detection**: Developing methods to identify AI-generated content while preserving utility




### Publications

<div class="publications">
{% bibliography -f papers %}
</div>

---

### Service

- External Reviewer for VLDB 2025
- PC member for ICLR 2024, NeurIPS 2025
- AE PC member of NDSS 2025, USENIX 2025, NDSS 2026
- Reviewer of IEEE Security & Privacy 2024
- PC member of ACM FAccT Conference 2022, 2023

---

### Selected Awards

- **Notable Reviewer** in ICLR 2025
- **Best Paper Award** in the 2023 ACM Conference on Fairness, Accountability, and Transparency (FAccT)
- **Research Achievement Award** in 2023 by NUS School of Computing
- **National University of Singapore Research Scholarship** (2018–2022)
- **First Prize** of the 10th National Information Security Competition (2017) on fake news detection for WeiBo
- **National Scholarship** (2015 & 2016, top 1%)


---


### Open-source Projects

- **Privacy Meter @ NUS**: A system for evaluating the privacy risks of machine learning models. <i class="fa-brands fa-github"></i> [GitHub](https://github.com/privacytrustlab/ml_privacy_meter) (500+ stars)  
  **My role**: leading the development team and spearheading the initial [1.0.1 release](https://pypi.org/project/Privacy-Meter/).

- **OpenFL @ Intel**: Auditing privacy risks in real-time. <i class="fa-brands fa-github"></i> [GitHub](https://github.com/intel/openfl/tree/develop/openfl-tutorials/experimental/Privacy_Meter). [Blogpost](https://www.intel.com/content/www/us/en/developer/articles/technical/how-openfl-and-privacy-meter-empower-data-privacy.html).  
  **My role**: leading the integration of privacy meter into OpenFL.

---

### Teaching Experience

- **Teaching Assistant** for Trustworthy Machine Learning (Summer 2021, 2022, 2023)
- **Teaching Assistant** for Computer Security (Spring and Summer 2020)
- **Teaching Assistant** for Introduction to Artificial Intelligence (Spring 2019)


---


### Talks

**Privacy in Federated Learning**
- USENIX, 2024

**Fairness in Federated Learning**
- FL@FM-Singapore, 2024
- Brave, 2024
- ICLR, 2024 (poster)
- N-CRiPT, 2023

**Trade-off in Privacy and Fairness**
- [Private AI Collaborative Research Institute](https://www.intel.com/content/www/us/en/research/blogs/private-ai-collaborative-research-institute-launch.html) held by Intel, 2022
- CyberSec&AI, 2021
- PrivacyCon, 2021 by the US Federal Trade Commission (FTC)


---

<div style="text-align: center; margin-top: 30px; font-size: 0.9em; color: #666;">
  <img src="https://hits.sh/changhongyan123.github.io.svg?style=flat&label=visitors&color=2698ba" alt="Visitor counter">
</div>
