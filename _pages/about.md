---
layout: about
title: about
permalink: /
# subtitle: Postdoc at MBZUAI. Trustworthy Machine Learning. Privacy & LLMs.

profile:
  align: right
  image: myself.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <div class="social" style="font-size: 1.5em; margin-top: 10px;">
      <a href="mailto:changhongyan0530@gmail.com" title="Email" style="margin-right: 15px;"><i class="fa-solid fa-envelope"></i></a>
      <a href="https://github.com/changhongyan123" title="GitHub" style="margin-right: 15px;"><i class="fa-brands fa-github"></i></a>
      <a href="https://scholar.google.com/citations?user=5d1AHgIAAAAJ" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
    </div>

selected_papers: false # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page

announcements:
  enabled: false # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

I am Hongyan Chang (Â∏∏Á∫¢Ááï), a postdoc at MBZUAI, working with Prof. [Ting Yu](https://mbzuai.ac.ae/study/faculty/ting-yu/). I obtained my Ph.D. from National University of Singapore working under the supervision of [Reza Shokri](https://www.comp.nus.edu.sg/~reza/).

My research interests are in trustworthy machine learning, with a focus on the privacy and accountability of large language models (LLMs):

- **Evaluating the risks of LLMs**: Understanding and quantifying vulnerabilities in modern language models and their applications
- **Machine-generated text detection**: Developing methods to identify AI-generated content while preserving utility




### Publications

- **Watermark Smoothing Attacks against Language Models**  
   **Hongyan Chang**, Hamed Hassani, and Reza Shokri  
   *WMARK@International Conference on Learning Representations (ICLR), 2025*

- **Context-Aware Membership Inference Attacks Against Pre-Trained Large Language Models**  
   **Hongyan Chang**, Ali Shahin Shamsabadi, Kleomenis Katevas, Hamed Haddadi, and Reza Shokri  
   *2024*

- **Efficient Privacy Auditing in Federated Learning**  
   **Hongyan Chang**, Brandon Edwards, Anindya S. Paul, and Reza Shokri  
   *USENIX Security Symposium (USENIX), 2024*  
   [[PDF](https://www.usenix.org/conference/usenixsecurity24/presentation/chang)] [[Code](https://github.com/changhongyan123/privacy_auditing_in_FL)]

- **On The Impact of Machine Learning Randomness on Group Fairness**  
   Prakhar Ganesh, **Hongyan Chang**, Martin Strobel, and Reza Shokri  
   *ACM Conference on Fairness, Accountability, and Transparency (FAccT), 2023*  
   üèÜ **Best Paper Award**  
   [[PDF](https://dl.acm.org/doi/10.1145/3593013.3594116)] [[Code](https://github.com/privacytrustlab/Data-Order-Randomness-versus-Group-Fairness)]

- **Bias Propagation in Federated Learning**  
   **Hongyan Chang** and Reza Shokri  
   *International Conference on Learning Representations (ICLR), 2023*  
   [[PDF](https://openreview.net/pdf?id=V7CYzdruWdm)] [[Code](https://github.com/privacytrustlab/bias_in_FL)]

- **Cronus: Robust and Heterogeneous Collaborative Learning with Black-box Knowledge Transfer**  
   **Hongyan Chang**\*, Virat Shejwalkar\*, Reza Shokri, and Amir Houmansadr  
   *NFFL@Neural Information Processing Systems (NeurIPS), 2021*  
   (*Equal contribution)  
   [[PDF](https://neurips2021workshopfl.github.io/NFFL-2021/papers/2021/Chang2021.pdf)]

- **On the Privacy Risks of Algorithmic Fairness**  
   **Hongyan Chang** and Reza Shokri  
   *6th IEEE European Symposium on Security and Privacy (Euro S&P), 2021*  
   [[PDF](https://arxiv.org/pdf/2011.03731)] [[Slides](https://www.ieee-security.org/TC/EuroSP2021/slides/Hongyan%20Chang%20-%20Hongyan%20Chang-On%20the%20Privacy%20Risks%20of%20Algorithmic%20Fairness.pdf)]

- **On Adversarial Bias and the Robustness of Fair Machine Learning**  
   **Hongyan Chang**, Ta Duy Nguyen, Sasi Kumar Murakonda, Ehsan Kazemi, and Reza Shokri  
   *2020*  
   [[PDF](https://arxiv.org/pdf/2006.08669)] [[Code](https://github.com/privacytrustlab/adversarial_bias)]

---

### Service

- External Reviewer for VLDB 2026
- PC member for ICLR 2024, NeurIPS 2025
- AE PC member of NDSS 2025, USENIX 2025, NDSS 2026
- Reviewer of IEEE Security & Privacy 2024
- PC member of ACM FAccT Conference 2022, 2023

---

### Selected Awards

- Notable Reviewer in ICLR 2025
- Research Achievement Award in 2023 by NUS School of Computing
- National University of Singapore Research Scholarship* (2018‚Äì2022)
- First Prize of the 10th National Information Security Competition (2017) on fake news detection for WeiBo
- National Scholarship (2015 & 2016, top 1%)


---


### Open-source Projects

- **Privacy Meter @ NUS**: A system for evaluating the privacy risks of machine learning models. <i class="fa-brands fa-github"></i> [GitHub](https://github.com/privacytrustlab/ml_privacy_meter) (500+ stars)  
  **My role**: leading the development team and spearheading the initial [1.0.1 release](https://pypi.org/project/Privacy-Meter/).

- **OpenFL @ Intel**: Auditing privacy risks in real-time. <i class="fa-brands fa-github"></i> [GitHub](https://github.com/intel/openfl/tree/develop/openfl-tutorials/experimental/Privacy_Meter). [Blogpost](https://www.intel.com/content/www/us/en/developer/articles/technical/how-openfl-and-privacy-meter-empower-data-privacy.html).  
  **My role**: leading the integration of privacy meter into OpenFL.

---

### Teaching Experience

- Teaching Assistant for Trustworthy Machine Learning (Summer 2021, 2022, 2023)
- Teaching Assistant for Computer Security (Spring and Summer 2020)
- Teaching Assistant for Introduction to Artificial Intelligence (Spring 2019)


---


### Talks

**Watermark in Large Language Models**
- WMARK@ICLR, 2025 (poster)

**Privacy in Federated Learning**
- USENIX, 2024

**Fairness in Federated Learning**
- FL@FM-Singapore, 2024
- Brave, 2024
- ICLR, 2024 (poster)
- N-CRiPT, 2023

**Trade-off in Privacy and Fairness**
- Private AI Collaborative Research Institute held by Intel, 2022
- CyberSec&AI, 2021
- PrivacyCon, 2021 by the US Federal Trade Commission (FTC)


---

<div style="text-align: center; margin-top: 30px; font-size: 0.9em; color: #666;">
  <img src="https://hits.sh/changhongyan123.github.io.svg?style=flat&label=visitors&color=2698ba" alt="Visitor counter">
</div>
