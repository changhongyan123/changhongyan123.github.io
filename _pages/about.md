---
layout: about
title: about
permalink: /
# subtitle: Postdoc at MBZUAI. Trustworthy Machine Learning. Privacy & LLMs.

profile:
  align: right
  image: myself.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <div class="social" style="font-size: 1.5em; margin-top: 10px;">
      <a href="mailto:changhongyan0530@gmail.com" title="Email" style="margin-right: 15px;"><i class="fa-solid fa-envelope"></i></a>
      <a href="https://github.com/changhongyan123" title="GitHub" style="margin-right: 15px;"><i class="fa-brands fa-github"></i></a>
      <a href="https://scholar.google.com/citations?user=5d1AHgIAAAAJ" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
    </div>

selected_papers: false # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page

announcements:
  enabled: false # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

I am **Hongyan Chang (Â∏∏Á∫¢Ááï)**, a postdoctoral researcher at MBZUAI, working with [Prof. Ting Yu](https://mbzuai.ac.ae/study/faculty/ting-yu/). I obtained my Ph.D. in Computer Science from the National University of Singapore, under the supervision of [Prof. Reza Shokri](https://www.comp.nus.edu.sg/~reza/). I received my Bachelor's degree in 2018 from the University of Electronic Science and Technology of China (UESTC), and was an exchange student at National Chiao Tung University in 2016.

My research interests are in trustworthy machine learning, with a focus on the privacy and accountability of large language models (LLMs):

- **Evaluating the risks of LLM systems**: Understanding and quantifying vulnerabilities in modern language models and their systems
- **Machine-generated text detection**: Developing methods to identify AI-generated content while preserving utility




### Publications

- **Watermark Smoothing Attacks against Language Models**  
   **Hongyan Chang**, Hamed Hassani, and Reza Shokri  
   *Empirical Methods in Natural Language Processing (EMNLP) Findings, 2025*  
   *WMARK@International Conference on Learning Representations (ICLR), 2025*  

- **Context-Aware Membership Inference Attacks Against Pre-Trained Large Language Models**  
   **Hongyan Chang**, Ali Shahin Shamsabadi, Kleomenis Katevas, Hamed Haddadi, and Reza Shokri  
   *Empirical Methods in Natural Language Processing (EMNLP) Main, 2025*

- **Efficient Privacy Auditing in Federated Learning**  
   **Hongyan Chang**, Brandon Edwards, Anindya S. Paul, and Reza Shokri  
   *USENIX Security Symposium (USENIX), 2024*  
   [[PDF](https://www.usenix.org/conference/usenixsecurity24/presentation/chang)] [[Code](https://github.com/changhongyan123/privacy_auditing_in_FL)]

- **On The Impact of Machine Learning Randomness on Group Fairness**  
   Prakhar Ganesh, **Hongyan Chang**, Martin Strobel, and Reza Shokri  
   *ACM Conference on Fairness, Accountability, and Transparency (FAccT), 2023*  
   üèÜ **Best Paper Award**  
   [[PDF](https://dl.acm.org/doi/10.1145/3593013.3594116)] [[Code](https://github.com/privacytrustlab/Data-Order-Randomness-versus-Group-Fairness)]

- **Bias Propagation in Federated Learning**  
   **Hongyan Chang** and Reza Shokri  
   *International Conference on Learning Representations (ICLR), 2023*  
   [[PDF](https://openreview.net/pdf?id=V7CYzdruWdm)] [[Code](https://github.com/privacytrustlab/bias_in_FL)]

- **Cronus: Robust and Heterogeneous Collaborative Learning with Black-box Knowledge Transfer**  
   **Hongyan Chang**\*, Virat Shejwalkar\*, Reza Shokri, and Amir Houmansadr  
   *NFFL@Neural Information Processing Systems (NeurIPS), 2021*  
   (*Equal contribution)  
   [[PDF](https://neurips2021workshopfl.github.io/NFFL-2021/papers/2021/Chang2021.pdf)]

- **On the Privacy Risks of Algorithmic Fairness**  
   **Hongyan Chang** and Reza Shokri  
   *6th IEEE European Symposium on Security and Privacy (Euro S&P), 2021*  
   [[PDF](https://arxiv.org/pdf/2011.03731)] [[Slides](https://www.ieee-security.org/TC/EuroSP2021/slides/Hongyan%20Chang%20-%20Hongyan%20Chang-On%20the%20Privacy%20Risks%20of%20Algorithmic%20Fairness.pdf)]

- **On Adversarial Bias and the Robustness of Fair Machine Learning**  
   **Hongyan Chang**, Ta Duy Nguyen, Sasi Kumar Murakonda, Ehsan Kazemi, and Reza Shokri  
   *2020*  
   [[PDF](https://arxiv.org/pdf/2006.08669)] [[Code](https://github.com/privacytrustlab/adversarial_bias)]

---

### PC services
<!-- - External Reviewer for VLDB 2026
- PC member for ICLR 2025, NeurIPS 2025, ICLR 2026 
- AE PC member of NDSS 2025, USENIX 2025, NDSS 2026
- Reviewer of IEEE Security & Privacy 2024 ([Certificate]({{ site.url }}{{ site.baseurl }}/assets/pdf/certificate.pdf))
- PC member of ACM FAccT Conference 2022, 2023
 -->

- 2026: VLDB (External Reviewer), ICLR (PC), NDSS (AE PC)  
- 2025: ICLR (PC), NeurIPS (PC), NDSS (AE PC), USENIX Security (AE PC)  
- 2024: IEEE Security & Privacy (Reviewer, [Certificate]({{ site.url }}{{ site.baseurl }}/assets/pdf/certificate.pdf))  
- 2023: ACM FAccT (PC)  
- 2022: ACM FAccT (PC)


---

### Selected Awards
- [Distinguished Reviewer Awards in USENIX 2025 (Artifact Evaluation)](https://secartifacts.github.io/usenixsec2025/awards#-distinguished-reviewer-awards:~:text=Hongyan%20Chang%2C%20National%20University%20of%20Singapore)
- [Notable Reviewer in ICLR 2025](https://iclr.cc/Conferences/2025/Reviewers)
- Best paper award at FAccT23 ([Certificate]({{ site.url }}{{ site.baseurl }}/assets/facct_award.pdf))
- Research Achievement Award in 2023 by NUS School of Computing
- National University of Singapore Research Scholarship (2018‚Äì2022)
- First Prize of the 10th National Information Security Competition (2017) on fake news detection for WeiBo
- National Scholarship (2015 & 2016, top 1%)


---


### Open-source Projects

- **Privacy Meter @ NUS**: A system for evaluating the privacy risks of machine learning models. <i class="fa-brands fa-github"></i> [GitHub](https://github.com/privacytrustlab/ml_privacy_meter) (500+ stars)  
  **My role**: leading the development team and spearheading the initial [1.0.1 release](https://pypi.org/project/Privacy-Meter/).

- **OpenFL @ Intel**: Auditing privacy risks in real-time. <i class="fa-brands fa-github"></i> [GitHub](https://github.com/intel/openfl/tree/develop/openfl-tutorials/experimental/Privacy_Meter). [Blogpost](https://www.intel.com/content/www/us/en/developer/articles/technical/how-openfl-and-privacy-meter-empower-data-privacy.html).  
  **My role**: leading the integration of privacy meter into OpenFL.

---

### Teaching Experience

- Teaching Assistant for Trustworthy Machine Learning (Summer 2021, 2022, 2023)
- Teaching Assistant for Computer Security (Spring and Summer 2020)
- Teaching Assistant for Introduction to Artificial Intelligence (Spring 2019)


---


### Talks

**Watermark in Large Language Models**
- WMARK@ICLR, 2025 (poster)

**Privacy in Federated Learning**
- USENIX, 2024

**Fairness in Federated Learning**
- FL@FM-Singapore, 2024
- Brave, 2024
- ICLR, 2024 (poster)
- N-CRiPT, 2023

**Trade-off in Privacy and Fairness**
- Private AI Collaborative Research Institute held by Intel, 2022
- CyberSec&AI, 2021
- PrivacyCon, 2021 by the **US Federal Trade Commission (FTC)**


---

<div style="text-align: center; margin-top: 30px; font-size: 0.9em; color: #666;">
  <img src="https://hits.sh/changhongyan123.github.io.svg?style=flat&label=visitors&color=2698ba" alt="Visitor counter">
</div>
