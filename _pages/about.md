---
layout: about
title: about
permalink: /
# subtitle: Postdoc at MBZUAI. Trustworthy Machine Learning. Privacy & LLMs.

profile:
  align: right
  image: myself.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <div class="social" style="font-size: 1.5em; margin-top: 10px;">
      <a href="mailto:changhongyan0530@gmail.com" title="Email" style="margin-right: 15px;"><i class="fa-solid fa-envelope"></i></a>
      <a href="https://github.com/changhongyan123" title="GitHub" style="margin-right: 15px;"><i class="fa-brands fa-github"></i></a>
      <a href="https://scholar.google.com/citations?user=5d1AHgIAAAAJ" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>
    </div>

selected_papers: false # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page

announcements:
  enabled: false # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

I am Hongyan Chang (Â∏∏Á∫¢Ááï), a postdoc at MBZUAI, working with Prof. [Ting Yu](https://mbzuai.ac.ae/study/faculty/ting-yu/). I obtained my Ph.D. from National University of Singapore working under the supervision of [Reza Shokri](https://www.comp.nus.edu.sg/~reza/).

My research interests are in trustworthy machine learning, with a focus on the privacy and accountability of large language models (LLMs):

- **Evaluating the risks of LLMs**: Understanding and quantifying vulnerabilities in modern language models and their applications
- **Machine-generated text detection**: Developing methods to identify AI-generated content while preserving utility




### Publications

1. **Watermark Smoothing Attacks against Language Models**  
   **Hongyan Chang**, Hamed Hassani, and Reza Shokri  
   *In WMARK, International Conference on Learning Representations (ICLR), 2025*

2. **Context-Aware Membership Inference Attacks Against Pre-Trained Large Language Models**  
   **Hongyan Chang**, Ali Shahin Shamsabadi, Kleomenis Katevas, Hamed Haddadi, and Reza Shokri  
   *2024*

3. **Efficient Privacy Auditing in Federated Learning**  
   **Hongyan Chang**, Ben Edwards, Anshuman Paul, and Reza Shokri  
   *In USENIX Security Symposium (USENIX), 2024*  
   [[PDF](https://www.usenix.org/conference/usenixsecurity24/presentation/chang)] [[Code](https://github.com/changhongyan123/privacy_auditing_in_FL)]

4. **Impact of Public Data on Private Image Classification**  
   Virat Shejwalkar, **Hongyan Chang** (equal contribution), Amir Houmansadr, and Reza Shokri  
   *In ICLR Workshop: Privacy and Security in ML (PSML), 2023*

5. **Cronus: Robust and Heterogeneous Collaborative Learning with Noisy Labels**  
   **Hongyan Chang**, Virat Shejwalkar (equal contribution), and Amir Houmansadr  
   *In Advances in Neural Information Processing Systems (NeurIPS), 2023*  
   üèÜ **Best Student Paper Award**

6. **Privacy and Robustness in Federated Learning: Attacks and Defenses**  
   Lingjuan Lyu, **Hongyan Chang**, Yaochen Xie, Ligeng Zhu, and Chen Lin  
   *2021*

7. **Fairness Without Demographics through Adversarially Reweighted Learning**  
   **Hongyan Chang**, Ta Duy Nguyen, Sasi Kumar Murakonda, Ehsan Kazemi, and Reza Shokri  
   *In International Conference on Machine Learning (ICML), 2021*

8. **On the Privacy Risks of Algorithmic Fairness**  
   **Hongyan Chang**, Reza Shokri, and Milad Nasr  
   *In European Symposium on Security and Privacy (EuroS&P), 2021*

---

### Service

- External Reviewer for VLDB 2025
- PC member for ICLR 2024, NeurIPS 2025
- AE PC member of NDSS 2025, USENIX 2025, NDSS 2026
- Reviewer of IEEE Security & Privacy 2024
- PC member of ACM FAccT Conference 2022, 2023

---

### Selected Awards

- **Notable Reviewer** in ICLR 2025
- **Best Paper Award** in the 2023 ACM Conference on Fairness, Accountability, and Transparency (FAccT)
- **Research Achievement Award** in 2023 by NUS School of Computing
- **National University of Singapore Research Scholarship** (2018‚Äì2022)
- **First Prize** of the 10th National Information Security Competition (2017) on fake news detection for WeiBo
- **National Scholarship** (2015 & 2016, top 1%)


---


### Open-source Projects

- **Privacy Meter @ NUS**: A system for evaluating the privacy risks of machine learning models. <i class="fa-brands fa-github"></i> [GitHub](https://github.com/privacytrustlab/ml_privacy_meter) (500+ stars)  
  **My role**: leading the development team and spearheading the initial [1.0.1 release](https://pypi.org/project/Privacy-Meter/).

- **OpenFL @ Intel**: Auditing privacy risks in real-time. <i class="fa-brands fa-github"></i> [GitHub](https://github.com/intel/openfl/tree/develop/openfl-tutorials/experimental/Privacy_Meter). [Blogpost](https://www.intel.com/content/www/us/en/developer/articles/technical/how-openfl-and-privacy-meter-empower-data-privacy.html).  
  **My role**: leading the integration of privacy meter into OpenFL.

---

### Teaching Experience

- **Teaching Assistant** for Trustworthy Machine Learning (Summer 2021, 2022, 2023)
- **Teaching Assistant** for Computer Security (Spring and Summer 2020)
- **Teaching Assistant** for Introduction to Artificial Intelligence (Spring 2019)


---


### Talks

**Privacy in Federated Learning**
- USENIX, 2024

**Fairness in Federated Learning**
- FL@FM-Singapore, 2024
- Brave, 2024
- ICLR, 2024 (poster)
- N-CRiPT, 2023

**Trade-off in Privacy and Fairness**
- [Private AI Collaborative Research Institute](https://www.intel.com/content/www/us/en/research/blogs/private-ai-collaborative-research-institute-launch.html) held by Intel, 2022
- CyberSec&AI, 2021
- PrivacyCon, 2021 by the US Federal Trade Commission (FTC)


---

<div style="text-align: center; margin-top: 30px; font-size: 0.9em; color: #666;">
  <img src="https://hits.sh/changhongyan123.github.io.svg?style=flat&label=visitors&color=2698ba" alt="Visitor counter">
</div>
